{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Suivi d'Objets avec YOLOv8\n",
        "Détection et suivi de tasses dans une séquence vidéo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration initiale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import subprocess\n",
        "# Configurations\n",
        "FRAMES_DIR = './TP3_data/MOT17/MOT17/train/MOT17-02-FRCNN/img1'\n",
        "INIT_FILE = './TP3_data/MOT17/MOT17/train/MOT17-02-FRCNN/gt/gt.txt'\n",
        "OUTPUT_FILE = 'results.txt'\n",
        "IOU_THRESHOLD = 0.6\n",
        "MAX_AGE = 5\n",
        "CLASS_NAME = 'cup'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Vérification des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Afficher les 5 premières frames\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    path = os.path.join(FRAMES_DIR, f'frame{i}.jpg')\n",
        "    if os.path.exists(path):\n",
        "        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Frame {i}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Classe de suivi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Track:\n",
        "    def __init__(self, track_id, bbox):\n",
        "        self.id = track_id\n",
        "        self.bbox = bbox  # [x1, y1, x2, y2]\n",
        "        self.age = 0\n",
        "    \n",
        "    def update(self, new_bbox):\n",
        "        self.bbox = new_bbox\n",
        "        self.age = 0\n",
        "    \n",
        "    def predict(self):\n",
        "        self.age += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialisation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger le modèle YOLOv8\n",
        "model = YOLO('yolo11n.pt')\n",
        "\n",
        "# Vérifier la classe 'cup'\n",
        "class_id = None\n",
        "for k, v in model.names.items():\n",
        "    if v == CLASS_NAME:\n",
        "        class_id = k\n",
        "        break\n",
        "    elif v == 'cups':\n",
        "        class_id = k\n",
        "        break\n",
        "        \n",
        "if class_id is None:\n",
        "    raise ValueError(f\"Classe '{CLASS_NAME}' non trouvée dans le modèle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Traitement principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: '1,1,912,484,97,109,0,7,1'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(INIT_FILE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m----> 5\u001b[0m         parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m         tracks\u001b[38;5;241m.\u001b[39mappend(Track(parts[\u001b[38;5;241m1\u001b[39m], [parts[\u001b[38;5;241m2\u001b[39m], parts[\u001b[38;5;241m3\u001b[39m], parts[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m+\u001b[39mparts[\u001b[38;5;241m4\u001b[39m], parts[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m+\u001b[39mparts[\u001b[38;5;241m5\u001b[39m]]))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Lister toutes les frames disponibles \u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '1,1,912,484,97,109,0,7,1'"
          ]
        }
      ],
      "source": [
        "# Initialiser les tracks\n",
        "tracks = []\n",
        "with open(INIT_FILE, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = list(map(int, line.strip().split()))\n",
        "        tracks.append(Track(parts[1], [parts[2], parts[3], parts[2]+parts[4], parts[3]+parts[5]]))\n",
        "\n",
        "# Lister toutes les frames disponibles \n",
        "frame_files = sorted([f for f in os.listdir(FRAMES_DIR) if f.lower().startswith('frame') and f.lower().endswith('.jpg')],key=lambda x: int(x[5:-4].lstrip('0') or 0))\n",
        "\n",
        "# Journal des résultats\n",
        "# Journal des résultats\n",
        "with open(OUTPUT_FILE, 'w') as results_file:\n",
        "    for frame_num, frame_file in enumerate(frame_files):\n",
        "        # Charger l'image\n",
        "        img = cv2.imread(os.path.join(FRAMES_DIR, frame_file))\n",
        "        \n",
        "        # Détection YOLOv8\n",
        "        detections = []\n",
        "        if frame_num > 0:\n",
        "            # Utiliser un seuil de confiance à 0.5 et filtrer par classe cup\n",
        "            results = model.predict(img, conf=0.5, classes=[class_id], verbose=False)\n",
        "            # Parcourir les détections en récupérant les scores\n",
        "            for box, conf in zip(results[0].boxes.xyxy.cpu().numpy(), results[0].boxes.conf.cpu().numpy()):\n",
        "                # Conversion des coordonnées en entiers\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                # Filtrage géométrique optionnel : on conserve les détections dont le ratio largeur/hauteur est raisonnable pour une tasse\n",
        "                width = x2 - x1\n",
        "                height = y2 - y1\n",
        "                if height > 0:\n",
        "                    ratio = width / height\n",
        "                    # On garde uniquement les détections avec un ratio entre 0.5 et 2.0\n",
        "                    if ratio < 0.8 or ratio > 2.0:\n",
        "                        continue\n",
        "                detections.append([x1, y1, x2, y2])\n",
        "        \n",
        "        # Matrice IoU\n",
        "        iou_matrix = np.zeros((len(tracks), len(detections)))\n",
        "        for t, track in enumerate(tracks):\n",
        "            for d, det in enumerate(detections):\n",
        "                a = track.bbox\n",
        "                b = det\n",
        "                inter = max(0, min(a[2], b[2]) - max(a[0], b[0])) * max(0, min(a[3], b[3]) - max(a[1], b[1]))\n",
        "                union = (a[2]-a[0])*(a[3]-a[1]) + (b[2]-b[0])*(b[3]-b[1]) - inter\n",
        "                iou_matrix[t, d] = inter / union if union > 0 else 0\n",
        "        \n",
        "        # Association des détections\n",
        "        row, col = linear_sum_assignment(-iou_matrix)\n",
        "        matched = set()\n",
        "        \n",
        "        # Mise à jour des tracks\n",
        "        for t, d in zip(row, col):\n",
        "            if iou_matrix[t, d] >= IOU_THRESHOLD:\n",
        "                tracks[t].update(detections[d])\n",
        "                matched.add(d)\n",
        "        \n",
        "        # Nouveaux tracks\n",
        "        for d in range(len(detections)):\n",
        "            if d not in matched and frame_num > 0:\n",
        "                new_id = max(t.id for t in tracks) + 1 if tracks else 1\n",
        "                tracks.append(Track(new_id, detections[d]))\n",
        "        \n",
        "        # Vieillissement des tracks\n",
        "        for track in tracks:\n",
        "            track.predict()\n",
        "        tracks = [t for t in tracks if t.age <= MAX_AGE]\n",
        "        \n",
        "        # Écrire les résultats\n",
        "        for track in tracks:\n",
        "            x1, y1, x2, y2 = track.bbox\n",
        "            results_file.write(f\"{frame_num} {track.id} {x1} {y1} {x2-x1} {y2-y1}\\n\")\n",
        "        \n",
        "        # Afficher le progrès\n",
        "        if frame_num % 50 == 0:\n",
        "            print(f\"Traitement: {frame_num}/{len(frame_files)} frames\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualisation des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vidéo sauvegardée sous result_video.avi\n"
          ]
        }
      ],
      "source": [
        "output_video = 'result_video.avi'\n",
        "fps = 20  # adjust fps as needed\n",
        "\n",
        "# Read the tracking results from results.txt\n",
        "# Each line format: frame_num track_id x y width height\n",
        "tracking_results = {}\n",
        "with open(OUTPUT_FILE, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 6:\n",
        "            continue\n",
        "        frame_num = int(parts[0])\n",
        "        track_id = int(parts[1])\n",
        "        x = int(parts[2])\n",
        "        y = int(parts[3])\n",
        "        w = int(parts[4])\n",
        "        h = int(parts[5])\n",
        "        tracking_results.setdefault(frame_num, []).append((track_id, x, y, w, h))\n",
        "\n",
        "# Get the sorted list of frame files\n",
        "frame_files = sorted(\n",
        "    [f for f in os.listdir(FRAMES_DIR) if f.lower().startswith('frame') and f.lower().endswith('.jpg')],\n",
        "    key=lambda x: int(x[5:-4].lstrip('0') or 0)\n",
        ")\n",
        "\n",
        "if not frame_files:\n",
        "    raise ValueError(\"No frame images found in the directory.\")\n",
        "\n",
        "# Get frame dimensions from the first frame\n",
        "first_frame = cv2.imread(os.path.join(FRAMES_DIR, frame_files[0]))\n",
        "height, width, _ = first_frame.shape\n",
        "\n",
        "# Initialize the video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "video_writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "# Process each frame, overlay tracking results, and write to the video\n",
        "for idx, frame_file in enumerate(frame_files):\n",
        "    frame = cv2.imread(os.path.join(FRAMES_DIR, frame_file))\n",
        "    \n",
        "    # Dessiner les boxes de suivi si disponibles pour la frame en cours\n",
        "    if idx in tracking_results:\n",
        "        for (track_id, x, y, w, h) in tracking_results[idx]:\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"ID {track_id}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5, (0, 255, 0), 2)\n",
        "    \n",
        "    video_writer.write(frame)\n",
        "\n",
        "video_writer.release()\n",
        "print(\"Vidéo sauvegardée sous\", output_video)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation avec TrackEval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici, nous préparons le fichier de résultats au format MOTChallenge complet et organisons\n",
        "le dossier de sortie pour TrackEval. Vous devrez adapter le nom de la séquence et du tracker.\n",
        "\n",
        "Par convention, nous utilisons :\n",
        "- Un fichier de résultats au format MOT dans 'results.txt' (déjà généré ci-dessus)\n",
        "- Nous le copions dans un fichier nommé results_MOT.txt (en respectant le format MOT à 10 colonnes)\n",
        "- La structure attendue par TrackEval sera :\n",
        "    TrackEval/data/trackers/mot_challenge/MOT17-train/<NomTracker>/<NomSequence>.txt\n",
        "\n",
        "Vous devez également disposer du dossier des vérités terrain pour MOT17 (ou MOT20) \n",
        "dans TrackEval/data/gt/mot_challenge/MOT17-train/<NomSequence>/gt.txt\n",
        "\n",
        "Réécriture optionnelle : ici nous copions directement le fichier OUTPUT_FILE en \n",
        "considérant que nous avons déjà écrit les 10 colonnes au bon format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier de résultats au format MOTChallenge généré : results_MOT.txt\n",
            "Résultats copiés vers TrackEval\\data\\trackers\\mot_challenge\\MOT17-train\\MonTracker\\MOT17-01.txt\n",
            "Lancement de l'évaluation avec TrackEval...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['python', 'TrackEval\\\\scripts\\\\run_mot_challenge.py', '--BENCHMARK', 'MOT17', '--SPLIT_TO_EVAL', 'train', '--TRACKERS_TO_EVAL', 'MonTracker', '--METRICS', 'HOTA'], returncode=2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_mot_file = 'results_MOT.txt'\n",
        "shutil.copy(OUTPUT_FILE, result_mot_file)\n",
        "print(f\"Fichier de résultats au format MOTChallenge généré : {result_mot_file}\")\n",
        "\n",
        "# Définir le nom de la séquence et du tracker (à ajuster)\n",
        "sequence_name = \"MOT17-01\"    # Remplacez par le nom réel de la séquence utilisée\n",
        "tracker_name = \"MonTracker\"   # Nom de votre tracker\n",
        "\n",
        "# Organiser la structure de dossier pour TrackEval\n",
        "# Exemple de structure pour MOT17-train :\n",
        "output_tracker_dir = os.path.join(\"TrackEval\", \"data\", \"trackers\", \"mot_challenge\", \"MOT17-train\", tracker_name)\n",
        "os.makedirs(output_tracker_dir, exist_ok=True)\n",
        "\n",
        "# Copier le fichier de résultats dans le dossier attendu par TrackEval\n",
        "tracker_result_file = os.path.join(output_tracker_dir, f\"{sequence_name}.txt\")\n",
        "shutil.copy(result_mot_file, tracker_result_file)\n",
        "print(f\"Résultats copiés vers {tracker_result_file}\")\n",
        "\n",
        "# Appel de l'évaluation TrackEval via un script\n",
        "# Nous supposons que le script d'évaluation se trouve dans 'TrackEval/scripts/run_mot_challenge.py'\n",
        "trackeval_script = os.path.join(\"TrackEval\", \"scripts\", \"run_mot_challenge.py\")\n",
        "benchmark = \"MOT17\"    # ou \"MOT20\" si applicable\n",
        "split = \"train\"\n",
        "cmd = [\n",
        "    \"python\", trackeval_script,\n",
        "    \"--BENCHMARK\", benchmark,\n",
        "    \"--SPLIT_TO_EVAL\", split,\n",
        "    \"--TRACKERS_TO_EVAL\", tracker_name,\n",
        "    \"--METRICS\", \"HOTA\"\n",
        "]\n",
        "print(\"Lancement de l'évaluation avec TrackEval...\")\n",
        "subprocess.run(cmd)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
